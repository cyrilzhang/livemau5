{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import laplace\n",
    "from skimage import feature\n",
    "from itertools import chain\n",
    "\n",
    "from load import *\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TestSet(): \n",
    "    def __init__(self):\n",
    "        files = []\n",
    "        for j in range(3,5):\n",
    "            prefix = '../data/AMG3_exp%d'%(j)\n",
    "            files.append( (prefix+'.tif', prefix+'.zip') )\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for i,(s,r) in enumerate(files):\n",
    "            self.data.append(load_stack(s))\n",
    "            self.labels.append(load_rois(r, 512, 512))\n",
    "\n",
    "def calc_f1_score((precision, recall)):\n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "def score(alg):\n",
    "    test_set = TestSet()\n",
    "    #predictions = alg().predict(test_set.data)\n",
    "    predictions = test_set.labels\n",
    "    assert(all([predictions[i].shape[1] == test_set.labels[i].shape[1] for i in range(len(test_set.labels))]))\n",
    "    assert(all([np.all(np.logical_or(predictions[i] == 1, predictions[i] == 0)) for i in range(len(predictions))]))\n",
    "    categorized = categorize(predictions, test_set.labels)\n",
    "    precisions, total_precision, recalls, total_recall = calc_precision_recall(categorized)\n",
    "    f1_scores = map(calc_f1_score, zip(precisions, recalls))\n",
    "    total_f1_score = calc_f1_score((total_precision, total_recall))\n",
    "    overlap_bqs, total_overlap_bq = overlap_boundary_quality(categorized)\n",
    "    print precisions, total_precision\n",
    "    print recalls, total_recall\n",
    "    print f1_scores, total_f1_score\n",
    "    print overlap_bqs, total_overlap_bq\n",
    "\n",
    "def calc_precision_recall(categorized):\n",
    "    num_fps = [len(categorized[i][\"fps\"]) for i in range(len(categorized))]\n",
    "    num_fns = [len(categorized[i][\"fns\"]) for i in range(len(categorized))]\n",
    "    num_pairs = [len(categorized[i][\"pairs\"]) for i in range(len(categorized))]\n",
    "    precisions = [num_pairs[i] / float(num_pairs[i] + num_fps[i]) for i in range(len(categorized))]\n",
    "    recalls = [num_pairs[i] / float(num_pairs[i] + num_fns[i]) for i in range(len(categorized))]\n",
    "    total_precision = sum(num_pairs) / float(sum(num_pairs) + sum(num_fps))\n",
    "    total_recall = sum(num_pairs) / float(sum(num_pairs) + sum(num_fns))\n",
    "    return precisions, total_precision, recalls, total_recall\n",
    "    \n",
    "def categorize(predictions, labels):\n",
    "    categorized = []\n",
    "    for i in range(len(predictions)):\n",
    "        categorized.append({\"fps\":[], \"fns\":[], \"pairs\":[]})\n",
    "        rois_pred, rois_true = list(predictions[i].copy()), list(labels[i].copy())\n",
    "        for roi_pred in rois_pred:\n",
    "            overlaps = map(lambda roi_true: calc_overlap(roi_pred, roi_true)[0], rois_true)\n",
    "            best_overlap, best_match = np.max(overlaps), rois_true[np.argmax(overlaps)]\n",
    "            if best_overlap > 0.5:\n",
    "                categorized[i][\"pairs\"].append((roi_pred, best_match))\n",
    "                rois_true.remove(best_match)\n",
    "            else:\n",
    "                categorized[i][\"fps\"].append(roi_pred)\n",
    "        for roi_true in rois_true:\n",
    "            categorized[i][\"fns\"].append(roi_true)\n",
    "    return categorized\n",
    "        \n",
    "def calc_overlap(roi_pred, roi_true):\n",
    "    intersection = np.sum(np.logical_and(roi_pred, roi_true))\n",
    "    union = np.sum(np.logical_or(roi_pred, roi_true))\n",
    "    if union == 0: \n",
    "        return 0, 0, 0\n",
    "    precision = intersection / float(np.sum(roi_pred))\n",
    "    recall = intersection / float(np.sum(roi_true))\n",
    "    general = intersection / float(union)\n",
    "    return general, precision, recall\n",
    "    \n",
    "def overlap_boundary_quality(categorized):\n",
    "    qualities = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for i in range(len(categorized)):\n",
    "        precisions.append([])\n",
    "        recalls.append([])\n",
    "        for roi_pred, roi_true in categorized[i][\"pairs\"]:\n",
    "            _, precision, recall = calc_overlap(roi_pred, roi_true)\n",
    "            precisions[i].append(precision)\n",
    "            recalls[i].append(recall)\n",
    "        qualities.append({\"mean precision\": np.mean(precisions[i]), \"std precision\": np.std(precisions[i]),\n",
    "                          \"mean recall\": np.mean(recalls[i]), \"std recall\": np.std(recalls[i])})\n",
    "    overall = {\"mean precision\": np.mean(list(chain.from_iterable(precisions))),\n",
    "               \"std precision\": np.std(list(chain.from_iterable(precisions))),\n",
    "               \"mean recall\": np.mean(list(chain.from_iterable(recalls))),\n",
    "               \"std recall\": np.std(list(chain.from_iterable(recalls)))}\n",
    "    return qualities, overall   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0] 1.0\n",
      "[1.0, 1.0] 1.0\n",
      "[1.0, 1.0] 1.0\n",
      "[{'std recall': 0.0, 'mean precision': 1.0, 'std precision': 0.0, 'mean recall': 1.0}, {'std recall': 0.0, 'mean precision': 1.0, 'std precision': 0.0, 'mean recall': 1.0}] {'std recall': 0.0, 'mean precision': 1.0, 'std precision': 0.0, 'mean recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "score(TestAlg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = np.zeros((2,3,3))\n",
    "n = np.zeros((2,3,3))\n",
    "m[0,0,0] = 1\n",
    "n[0,0,0] = 1\n",
    "n[1,2,2] = 1\n",
    "m[1,1,1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  1.  0.]\n",
      "  [ 0.  0.  0.]]]\n",
      "[[[ 1.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]\n",
      "  [ 0.  0.  1.]]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:68: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:67: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fns': [array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.])],\n",
       "  'fps': [array([ 0.,  0.,  0.]), array([ 0.,  0.,  0.])],\n",
       "  'pairs': [(array([ 1.,  0.,  0.]), array([ 1.,  0.,  0.]))]},\n",
       " {'fns': [array([ 0.,  0.,  0.]),\n",
       "   array([ 0.,  0.,  0.]),\n",
       "   array([ 0.,  0.,  1.])],\n",
       "  'fps': [array([ 0.,  0.,  0.]),\n",
       "   array([ 0.,  1.,  0.]),\n",
       "   array([ 0.,  0.,  0.])],\n",
       "  'pairs': []}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print m\n",
    "print n\n",
    "print\n",
    "print\n",
    "categorize(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
